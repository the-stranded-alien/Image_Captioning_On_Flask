{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning\n",
    "- Generating Captions for Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Data Collection\n",
    "- Understanding the Data\n",
    "- Data Cleaning\n",
    "- Loading The Training Set\n",
    "- Data Preprocessing - Images\n",
    "- Data Preprocessing - Captions\n",
    "- Data Preparation using Generator Function\n",
    "- Word Embeddings\n",
    "- Model Architecture\n",
    "- Inference\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import collections\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Text Captions\n",
    "\n",
    "def readTextFile(path):\n",
    "    with open(path) as f:\n",
    "        captions = f.read()\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = readTextFile(\"./Flickr_Data/Flickr_TextData/Flickr8k.token.txt\")\n",
    "captions = captions.split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(captions[0].split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to Map Each Image With The List Of Captions It Has\n",
    "\n",
    "descriptions = {}\n",
    "\n",
    "for x in captions:\n",
    "    first_part, second_part = x.split('\\t')\n",
    "    img_name = first_part.split('.')[0]\n",
    "    \n",
    "    # if the image id is already present or not\n",
    "    if descriptions.get(img_name) is None:\n",
    "        descriptions[img_name] = []\n",
    "    \n",
    "    descriptions[img_name].append(second_part)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"Flickr_Data/Images/\"\n",
    "img = cv2.imread(IMG_PATH + \"1000268201_693b08cb0e.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z]+\", \" \", sentence)\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    sentence = [s for s in sentence if len(s) > 1]\n",
    "    sentence = \" \".join(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_text(\"A cat is sitting over the house # 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean All Captions\n",
    "\n",
    "for key, caption_list in descriptions.items():\n",
    "    for i in range(len(caption_list)):\n",
    "        caption_list[i] = clean_text(caption_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to text file\n",
    "\n",
    "with open(\"descriptions_1.txt\",\"w\") as f:\n",
    "    f.write(str(descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = None\n",
    "with open(\"descriptions_1.txt\",'r') as f:\n",
    "    descriptions = f.read()\n",
    "    \n",
    "json_acceptable_string = descriptions.replace(\"'\", \"\\\"\")\n",
    "descriptions = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "\n",
    "vocab = set()\n",
    "for key in descriptions.keys():\n",
    "    [vocab.update(sentence.split()) for sentence in descriptions[key]]\n",
    "print(\"Vocab Size : %d\"%len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total No. of Words Across All The Sentences\n",
    "\n",
    "total_words = []\n",
    "\n",
    "for key in descriptions.keys():\n",
    "    [total_words.append(i) for des in descriptions[key] for i in des.split()]\n",
    "    \n",
    "print(\"Total Words %d\"%len(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Words From the Vocab according to certain threshold frequency\n",
    "\n",
    "counter = collections.Counter(total_words)\n",
    "freq_cnt = dict(counter)\n",
    "print(len(freq_cnt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort this dictionary according to the frequency count\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(), reverse=True, key=lambda x:x[1])\n",
    "\n",
    "# Filter\n",
    "threshold = 10\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1] > threshold]\n",
    "total_words = [x[0] for x in sorted_freq_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(total_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_data = readTextFile(\"Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt\")\n",
    "test_file_data = readTextFile(\"Flickr_Data/Flickr_TextData/Flickr_8k.testImages.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [row.split(\".\")[0] for row in train_file_data.split(\"\\n\")[:-1]]\n",
    "test = [row.split(\".\")[0] for row in test_file_data.split(\"\\n\")[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Description for The Training Data\n",
    "# Tweak - Add <s> and <e> token to our training data\n",
    "\n",
    "train_descriptions = {}\n",
    "\n",
    "for img_id in train:\n",
    "    train_descriptions[img_id] = []\n",
    "    for cap in descriptions[img_id]:\n",
    "        cap_to_append = \"startseq \" + cap + \" endseq\"\n",
    "        train_descriptions[img_id].append(cap_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning \n",
    "- Images ----> Features\n",
    "- Text ------> Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - 1 : Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights = \"imagenet\", input_shape=(224,224,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img = image.load_img(img, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    # Normalisation\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_img(IMG_PATH + \"1000268201_693b08cb0e.jpg\")\n",
    "plt.imshow(img[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(img):\n",
    "    img = preprocess_img(img)\n",
    "    feature_vector = model_new.predict(img)\n",
    "    feature_vector = feature_vector.reshape((-1,))\n",
    "    # print(feature_vector.shape)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_image(IMG_PATH + \"1000268201_693b08cb0e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_train = {}\n",
    "start_time = time()\n",
    "# image_id --> feature_vector extracted from Resnet Image\n",
    "\n",
    "for ix, img_id in enumerate(train):\n",
    "    img_path = IMG_PATH + \"/\" + img_id + \".jpg\"\n",
    "    encoding_train[img_id] = encode_image(img_path)\n",
    "    if ix % 100 == 0:\n",
    "        print(\"Encoding in Progress Time Step : %d\"%ix)\n",
    "        \n",
    "end_time = time()\n",
    "print(\"Total Time Taken : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Everything To Disk\n",
    "\n",
    "with open(\"encoded_train_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoding_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_test = {}\n",
    "start_time = time()\n",
    "# image_id --> feature_vector extracted from Resnet Image\n",
    "\n",
    "for ix, img_id in enumerate(test):\n",
    "    img_path = IMG_PATH + \"/\" + img_id + \".jpg\"\n",
    "    encoding_test[img_id] = encode_image(img_path)\n",
    "    if ix % 100 == 0:\n",
    "        print(\"Test Encoding in Progress Time Step : %d\"%ix)\n",
    "        \n",
    "end_time = time()\n",
    "print(\"Total Time Taken (Test) : \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encoded_test_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoding_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing For Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocab\n",
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for i, word in enumerate(total_words):\n",
    "    word_to_idx[word] = i+1\n",
    "    idx_to_word[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_to_word[1]\n",
    "# word_to_idx[\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(idx_to_word))\n",
    "print(len(word_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Special Words\n",
    "\n",
    "idx_to_word[1846] = 'startseq'\n",
    "word_to_idx['startseq'] = 1846\n",
    "\n",
    "idx_to_word[1847] = 'endseq'\n",
    "word_to_idx['endseq'] = 1847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_idx) + 1\n",
    "print(\"Vocab Size : %d\"%vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for key in train_descriptions.keys():\n",
    "    for cap in train_descriptions[key]:\n",
    "        max_len = max(max_len, len(cap.split()))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./storage/word_to_idx.pkl\", \"wb\") as w2i:\n",
    "    pickle.dump(word_to_idx, w2i)\n",
    "\n",
    "with open(\"./storage/idx_to_word.pkl\", \"wb\") as i2w:\n",
    "    pickle.dump(idx_to_word, i2w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader (Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(train_descriptions, encoding_train, word_to_idx, max_len, batch_size):\n",
    "    \n",
    "    X1, X2, Y = [], [], []\n",
    "    \n",
    "    n = 0\n",
    "    while True:\n",
    "        for key, desc_list in train_descriptions.items():\n",
    "            n += 1\n",
    "            \n",
    "            photo = encoding_train[key]\n",
    "            for desc in desc_list:\n",
    "                seq = [word_to_idx[word] for word in desc.split() if word in word_to_idx]\n",
    "                for i in range(1, len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "                    # 0 denotes padding word\n",
    "                    xi = pad_sequences([xi], maxlen=max_len, value=0, padding='post')[0]\n",
    "                    yi = to_categorical([yi], num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    X1.append(photo)\n",
    "                    X2.append(xi)\n",
    "                    Y.append(yi)\n",
    "                    \n",
    "                if n == batch_size:\n",
    "                    yield [[np.array(X1), np.array(X2)], np.array(Y)]\n",
    "                    X1, X2, Y= [], [], []\n",
    "                    n = 0               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"glove.6B.50d.txt\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:], dtype='float')\n",
    "    embedding_index[word] = word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index[\"apple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix():\n",
    "    emb_dim = 50\n",
    "    matrix = np.zeros((vocab_size, emb_dim))\n",
    "    for word, idx in word_to_idx.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            matrix[idx] = embedding_vector\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedding_matrix()\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix[1847]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_features = Input(shape=(2048,))\n",
    "inp_img1 = Dropout(0.3)(input_img_features)\n",
    "inp_img2 = Dense(256, activation='relu')(inp_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captions as Input\n",
    "input_captions = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=vocab_size, output_dim=50, mask_zero=True)(input_captions)\n",
    "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder1 = add([inp_img2, inp_cap3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "# Combined Model\n",
    "model = Model(inputs=[input_img_features, input_captions], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Thing -> Embedding Layer\n",
    "\n",
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 3\n",
    "steps = len(train_descriptions)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, batch_size)\n",
    "    model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
    "    model.save('./model_weights/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model_weights/model_9.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(photo):\n",
    "    \n",
    "    in_text = \"startseq\"\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_len, padding='post')\n",
    "        \n",
    "        ypred = model.predict([photo,sequence])\n",
    "        ypred = ypred.argmax() # Taking word with max prob always - Greedy Sampling\n",
    "        word = idx_to_word[ypred]\n",
    "        in_text += ' ' + word\n",
    "        \n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    \n",
    "    final_caption = in_text.split()[1:-1]\n",
    "    final_caption = ' '.join(final_caption)\n",
    "    \n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick some random images and See Results\n",
    "\n",
    "for i in range(15):\n",
    "    idx = np.random.randint(0,1000)\n",
    "    all_img_names = list(encoding_test.keys())\n",
    "    img_name = all_img_names[idx]\n",
    "    photo_2048 = encoding_test[img_name].reshape((1,2048))\n",
    "    \n",
    "    i = plt.imread(\"Flickr_Data/Images/\" + img_name + \".jpg\")\n",
    "    caption = predict_caption(photo_2048)\n",
    "    print(caption)\n",
    "    plt.imshow(i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
